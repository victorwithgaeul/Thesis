{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Built-in Self Checking for Winograd Convolution</center>\n",
    "<center>T.-C. Huang</center>\n",
    "<center>2022/07/11</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) References\n",
    "\n",
    "[1] https://en.wikipedia.org/wiki/Computational_complexity_of_matrix_multiplication\n",
    "\n",
    "[2] https://medium.com/@dmangla3/understanding-winograd-fast-convolution-a75458744ff\n",
    "\n",
    "[3] Lavin, A. and Gray, S., “Fast Algorithms for Convolutional Neural Networks”, <i>arXiv e-prints</i>, 2015.\n",
    "\n",
    "[4] D. Coppersmith; S. Winograd (1981). \"On the asymptotic complexity of matrix multiplication\". Proc. 22nd Annual Symposium on Foundations of Computer Science (FOCS). pp. 82–90.\n",
    "\n",
    "[5] D. Coppersmith; S. Winograd (Mar 1990). \"Matrix multiplication via arithmetic progressions\". Journal of Symbolic Computation. 9 (3): 251–280.\n",
    "\n",
    "[6] https://blog.csdn.net/qq_40268672/article/details/116563105\n",
    "\n",
    "[7] https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123640052.pdf\n",
    "\n",
    "[8] https://libs.garden/python?sort=popular\n",
    "\n",
    "[9] https://www.youtube.com/watch?v=Lq09o6xEem4\n",
    "\n",
    "[10] https://arxiv.org/pdf/1509.09308.pdf\n",
    "\n",
    "[11] https://github.com/andravin/wincnn\n",
    "\n",
    "[12] Y. Liang, L. Lu, Q. Xiao and S. Yan, \"Evaluating Fast Algorithms for Convolutional Neural Networks on FPGAs,\" in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, vol. 39, no. 4, pp. 857-870, April 2020, doi: 10.1109/TCAD.2019.\n",
    "\n",
    "[13] Barabasz, B., Anderson, A., Soodhalter, K. M., and Gregg, D., “Error Analysis and Improving the Accuracy of Winograd Convolution for Deep Neural Networks”, <i>arXiv e-prints</i>, 2018.\n",
    "\n",
    "[14] G. Panda, R. Pal and B. Chatterjee, \"Fixed-point error analysis of Winograd basic DFT algorithms considering correlation between noise sources,\" ICASSP '81. IEEE International Conference on Acoustics, Speech, and Signal Processing, 1981, pp. 1184-1188,\n",
    "\n",
    "[15] Xue, X., Huang, H., Liu, C., Wang, Y., Luo, T., and Zhang, L., “Winograd Convolution: A Perspective from Fault Tolerance”, <i>arXiv e-prints</i>, 2022. (**major compared reference**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 1D Convolution\n",
    "\n",
    "For a ($m+r-1$)-input, filtered by a $r$-sized kernel and $m$-output one-dimensional (1D) convolution, the minimal count of required multiplications is\n",
    "\n",
    "$\\mu(F(m, r)) = m+r-1$.\n",
    "\n",
    "However, the conventional methods of matrix multiplication requires $mr$ scalar multiplications.\n",
    "\n",
    "#### (1.1) Simple Example\n",
    "\n",
    "$F(2, 3)=\\begin{bmatrix}\n",
    "d_0 & d_1 & d_2 \\\\\n",
    "d_1 & d_2 & d_3 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "g_0 \\\\ g_1 \\\\ g_2 \\\\\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "d_0 g_0 + d_1 g_1 + d_2 g_2 \\\\\n",
    "d_1 g_0 + d_2 g_1 + d_3 g_2 \\\\\n",
    "\\end{bmatrix}\n",
    "$, the count of multiplications is $2\\times 3 = 6$.\n",
    "\n",
    "#### (1.2) Winograd Method for the 1D Simple Example\n",
    "\n",
    "Let input data vector $d=\\begin{bmatrix} d_0 & d_1 & d_2 & d_3 \\\\ \\end{bmatrix}^T = \\begin{bmatrix} d_0\\\\ d_1\\\\ d_2\\\\ d_3 \\\\ \\end{bmatrix}$, \n",
    "\n",
    "convolution kernel (filter) $\\bf{g}=\\begin{bmatrix} g_0 & g_1 & g_2 \\\\ \\end{bmatrix}^T = \\begin{bmatrix} g_0\\\\ g_1\\\\ g_2 \\\\ \\end{bmatrix}$,\n",
    "\n",
    "select a **filter transform** $G=\\begin{bmatrix} 1& 0& 0 \\\\ 0.5& 0.5& 0.5 \\\\ 0.5& -0.5& 0.5 \\\\ 0& 0& 1 \\\\ \\end{bmatrix}$, we have \n",
    "$Gg=\\begin{bmatrix} 1& 0& 0 \\\\ 0.5& 0.5& 0.5 \\\\ 0.5& -0.5& 0.5 \\\\ 0& 0& 1 \\\\ \\end{bmatrix}\\begin{bmatrix} g_0\\\\ g_1\\\\ g_2 \\\\ \\end{bmatrix}\n",
    "= \\begin{bmatrix} g_0 \\\\ (g_0+g_1+g_2)/2 \\\\ (g_0-g_1+g_2)/2 \\\\ g_3 \\\\ \\end{bmatrix}$.\n",
    "\n",
    "Find **Input Transform** $B^T = \\begin{bmatrix} 1& 0& 0 \\\\ 0.5& 0.5& 0.5 \\\\ 0.5& -0.5& 0.5 \\\\ 0& 0& 1 \\\\ \\end{bmatrix}$, and \n",
    "\n",
    "**Output Transform** $A^T = \\begin{bmatrix} 1 & 1 & 1 & 0 \\\\ 0 & 1 & -1 & -1 \\\\ \\end{bmatrix}$, such that\n",
    "\n",
    "$Y = A^T[(Gg)\\odot(B^Td)]$, where operator $\\odot$ is the element-wise multiplication（Hadamard product).\n",
    "\n",
    "Then the calculation $Y$ can reduce the count of multiplications from $mn$ to $m+n-1$,\n",
    "\n",
    "and the convolution will be\n",
    "\n",
    "$Y = \\begin{bmatrix} m_1 + m_2 + m_3 \\\\ m_2 - m_3 - m_4 \\\\ \\end{bmatrix}$.\n",
    "\n",
    "#### (1.3) Python Code for the Simple Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT = \n",
      "⎡1  1  1   0⎤\n",
      "⎢           ⎥\n",
      "⎣0  2  -1  1⎦\n",
      "\n",
      "G = \n",
      "⎡1/2   0     0 ⎤\n",
      "⎢              ⎥\n",
      "⎢1/6  1/3   2/3⎥\n",
      "⎢              ⎥\n",
      "⎢1/3  -1/3  1/3⎥\n",
      "⎢              ⎥\n",
      "⎣ 0    0     1 ⎦\n",
      "\n",
      "BT = \n",
      "⎡2  1   -1  0⎤\n",
      "⎢            ⎥\n",
      "⎢0  1   1   0⎥\n",
      "⎢            ⎥\n",
      "⎢0  -2  1   0⎥\n",
      "⎢            ⎥\n",
      "⎣0  -2  -1  1⎦\n",
      "\n",
      "FIR filter: AT*((G*g)(BT*d)) =\n",
      "⎡d[0]⋅g[0] + d[1]⋅g[1] + d[2]⋅g[2]⎤\n",
      "⎢                                 ⎥\n",
      "⎣d[1]⋅g[0] + d[2]⋅g[1] + d[3]⋅g[2]⎦\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Reference: https://github.com/andravin/wincnn\n",
    "import wincnn\n",
    "# output size m = 2, filter size = 3\n",
    "wincnn.showCookToomFilter((0, 2, -1), 2, 3)\n",
    "# Note that the vector (1, -1, 0) is a part of the second row of output transform AT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy flip convolve =  [ 0.6   -2.21   2.775 -1.75   0.53  -0.1  ]\n",
      "numpy product =  [2.775, -1.75]\n",
      "AT= [[ 1  1  1  0]\n",
      " [ 0  1 -1  1]]\n",
      "G = [[ 1.   0.   0. ]\n",
      " [ 0.5  0.5  0.5]\n",
      " [ 0.5 -0.5  0.5]\n",
      " [ 0.   0.   1. ]]\n",
      "BT= [[ 1  0 -1  0]\n",
      " [ 0  1  1  0]\n",
      " [ 0 -1  1  0]\n",
      " [ 0 -1  0  1]]\n",
      "Gg= [0.25  0.775 1.475 2.   ]\n",
      "BTd [-0.7  0.   2.   0.6]\n",
      "Gg*BTd= [-0.175  0.     2.95   1.2  ]\n",
      "ATx(Gg*BTD)= [ 2.775 -1.75 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "d = np.array([0.3, -1.0, 1, -0.4])\n",
    "g = np.array([0.25, -0.7, 2])\n",
    "cv = np.convolve(d, np.flip(g))\n",
    "print(\"numpy flip convolve = \", cv)\n",
    "mu = [np.matmul(d[0:3], g), np.matmul(d[1:4], g)]\n",
    "print(\"numpy product = \", mu)\n",
    "AT = np.array([[1, 1, 1, 0], [0, 1, -1, 1]]) #### Note: elements of BT are in {1, -1, 0} so that there is no multiplications\n",
    "G = np.array([[1, 0, 0], [1/2, 1/2, 1/2], [1/2, -1/2, 1/2], [0, 0, 1]])\n",
    "BT = np.array([[1, 0, -1, 0], [0, 1, 1, 0], [0, -1, 1, 0], [0, -1, 0, 1]]) #### Note: elements of BT are in {1, -1, 0} so that there is no multiplications\n",
    "Gg = np.matmul(G, g) #### constants that can be found in advance.\n",
    "BTd = np.matmul(BT, d) \n",
    "print(\"AT=\", AT)\n",
    "print(\"G =\", G)\n",
    "print(\"BT=\", BT)\n",
    "print(\"Gg=\", Gg)\n",
    "print(\"BTd\", BTd)\n",
    "print(\"Gg*BTd=\", Gg*BTd)\n",
    "print(\"ATx(Gg*BTD)=\", np.matmul(AT, Gg * BTd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1.4) Round-Off AN-Code Encoder\n",
    "\n",
    "* **AN Codes** also called **Product Codes**, are encoded by multiplying an integer multiplier <b>M</b> , (sometimes denoted as **A** instead).\n",
    "* When AN Codes are used in self-checking, the **aliasing rate** will be $1/M$.\n",
    "* If $M$ is a perfect prime number, for an error $e$ in a (mod $M$) system, the residue $e$ can allocate $(M-1)/2$ positions of **single arithmetic weight error**.\n",
    "* Therefore we should multiply an integer $M$ in advance, however, it will increase the **dynamic range** (DR), and thus longer bits and operations.\n",
    "* We will *truncate* the constant transformed filter $Gg$ to dividible by $M$ by $[Gg/M]M$, where the square brackets $[ ]$ denote the roundoff operator.\n",
    "* Usually, $M$ is selected as $2^n-1$ for self-checking. The decoded result is also called **check-sum** in this case.\n",
    "* For $m$-bit integers, say $x=\\Sigma_{i=0}^{m-1}x_i\\cdot 2^i$, where $m>n$ and $\\lceil m/n\\rceil = k$ such that $x = \\Sigma_{j=0}^{k-1}y_j\\cdot 2^{jn}$ and $y_j = \\Sigma_{i=0}^{n-1} x_{jn+i}\\cdot 2^i$. Then $x = \\Sigma_{j=0}^k y_j \\ \\ (mod M)$\n",
    "* For $k=4$, the checksum decoder will be a 4-input $n$-bit parallel adder with an adder and a half-adder. For self-checking only, the error syndrome can be decided by the parallel adder, so the rest adder and half adder can be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25 , 0.775, 1.475, 2.   ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1.5) More Complex Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT = \n",
      "⎡1  1  1   1  1   0⎤\n",
      "⎢                  ⎥\n",
      "⎢0  1  -1  2  -2  0⎥\n",
      "⎢                  ⎥\n",
      "⎢0  1  1   4  4   0⎥\n",
      "⎢                  ⎥\n",
      "⎣0  1  -1  8  -8  1⎦\n",
      "\n",
      "G = \n",
      "⎡1/4     0     0  ⎤\n",
      "⎢                 ⎥\n",
      "⎢-1/6  -1/6   -1/6⎥\n",
      "⎢                 ⎥\n",
      "⎢-1/6   1/6   -1/6⎥\n",
      "⎢                 ⎥\n",
      "⎢1/24  1/12   1/6 ⎥\n",
      "⎢                 ⎥\n",
      "⎢1/24  -1/12  1/6 ⎥\n",
      "⎢                 ⎥\n",
      "⎣ 0      0     1  ⎦\n",
      "\n",
      "BT = \n",
      "⎡4  0   -5  0   1  0⎤\n",
      "⎢                   ⎥\n",
      "⎢0  -4  -4  1   1  0⎥\n",
      "⎢                   ⎥\n",
      "⎢0  4   -4  -1  1  0⎥\n",
      "⎢                   ⎥\n",
      "⎢0  -2  -1  2   1  0⎥\n",
      "⎢                   ⎥\n",
      "⎢0  2   -1  -2  1  0⎥\n",
      "⎢                   ⎥\n",
      "⎣0  4   0   -5  0  1⎦\n",
      "\n",
      "FIR filter: AT*((G*g)(BT*d)) =\n",
      "⎡d[0]⋅g[0] + d[1]⋅g[1] + d[2]⋅g[2]⎤\n",
      "⎢                                 ⎥\n",
      "⎢d[1]⋅g[0] + d[2]⋅g[1] + d[3]⋅g[2]⎥\n",
      "⎢                                 ⎥\n",
      "⎢d[2]⋅g[0] + d[3]⋅g[1] + d[4]⋅g[2]⎥\n",
      "⎢                                 ⎥\n",
      "⎣d[3]⋅g[0] + d[4]⋅g[1] + d[5]⋅g[2]⎦\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Givne #output = m, |filter|=r=3, the first two rows of AT are [1, 1, 1, 1, 1, 0; 0, 1, -1, 2, -2, 0]\n",
    "wincnn.showCookToomFilter((0,1, -1, 2, -2), 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT = \n",
      "⎡1  1  1   1    1    1      1    0⎤\n",
      "⎢                                 ⎥\n",
      "⎢0  1  -1  2   -2   1/2   -1/2   0⎥\n",
      "⎢                                 ⎥\n",
      "⎢0  1  1   4    4   1/4    1/4   0⎥\n",
      "⎢                                 ⎥\n",
      "⎢0  1  -1  8   -8   1/8   -1/8   0⎥\n",
      "⎢                                 ⎥\n",
      "⎢0  1  1   16  16   1/16  1/16   0⎥\n",
      "⎢                                 ⎥\n",
      "⎣0  1  -1  32  -32  1/32  -1/32  1⎦\n",
      "\n",
      "G = \n",
      "⎡ 1      0     0  ⎤\n",
      "⎢                 ⎥\n",
      "⎢-2/9  -2/9   -2/9⎥\n",
      "⎢                 ⎥\n",
      "⎢-2/9   2/9   -2/9⎥\n",
      "⎢                 ⎥\n",
      "⎢1/90  1/45   2/45⎥\n",
      "⎢                 ⎥\n",
      "⎢1/90  -1/45  2/45⎥\n",
      "⎢                 ⎥\n",
      "⎢ 32    16        ⎥\n",
      "⎢ ──    ──    8/45⎥\n",
      "⎢ 45    45        ⎥\n",
      "⎢                 ⎥\n",
      "⎢ 32   -16        ⎥\n",
      "⎢ ──   ────   8/45⎥\n",
      "⎢ 45    45        ⎥\n",
      "⎢                 ⎥\n",
      "⎣ 0      0     1  ⎦\n",
      "\n",
      "BT = \n",
      "⎡1   0    -21/4    0    21/4     0    -1  0⎤\n",
      "⎢                                          ⎥\n",
      "⎢0   1      1    -17/4  -17/4    1    1   0⎥\n",
      "⎢                                          ⎥\n",
      "⎢0   -1     1    17/4   -17/4   -1    1   0⎥\n",
      "⎢                                          ⎥\n",
      "⎢0  1/2    1/4   -5/2   -5/4     2    1   0⎥\n",
      "⎢                                          ⎥\n",
      "⎢0  -1/2   1/4    5/2   -5/4    -2    1   0⎥\n",
      "⎢                                          ⎥\n",
      "⎢0   2      4    -5/2    -5     1/2   1   0⎥\n",
      "⎢                                          ⎥\n",
      "⎢0   -2     4     5/2    -5    -1/2   1   0⎥\n",
      "⎢                                          ⎥\n",
      "⎣0   -1     0    21/4     0    -21/4  0   1⎦\n",
      "\n",
      "FIR filter: AT*((G*g)(BT*d)) =\n",
      "⎡d[0]⋅g[0] + d[1]⋅g[1] + d[2]⋅g[2]⎤\n",
      "⎢                                 ⎥\n",
      "⎢d[1]⋅g[0] + d[2]⋅g[1] + d[3]⋅g[2]⎥\n",
      "⎢                                 ⎥\n",
      "⎢d[2]⋅g[0] + d[3]⋅g[1] + d[4]⋅g[2]⎥\n",
      "⎢                                 ⎥\n",
      "⎢d[3]⋅g[0] + d[4]⋅g[1] + d[5]⋅g[2]⎥\n",
      "⎢                                 ⎥\n",
      "⎢d[4]⋅g[0] + d[5]⋅g[1] + d[6]⋅g[2]⎥\n",
      "⎢                                 ⎥\n",
      "⎣d[5]⋅g[0] + d[6]⋅g[1] + d[7]⋅g[2]⎦\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sympy import Rational\n",
    "wincnn.showCookToomFilter((0,1,-1,2,-2,Rational(1,2),-Rational(1,2)), 6, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 2D Convolution\n",
    "\n",
    "#### (2.1) Square Example\n",
    "\n",
    "A minimal 1D algorithm $F(m, r)$ can be nested with itself to obtain a minimal 2D algorithm, $F(m\\times m, r\\times r)$ like so \n",
    "\n",
    "$Y = A^T[[GgG^T]\\odot [B^TdB]]A, where $g$ is an $r\\times r$ filter and $d$ is an $(m+r−1)\\times (m+r−1)$ image tile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2.2) Rectangle Example\n",
    "\n",
    "Algorithms for $F(m\\times m, r\\times r)$ can be used to compute convnet layers with $r\\times r$ kernels.  Each image channel is divided into tiles of size $(m+r−1)\\times (m+r−1)$, with $r−1$ elements of overlap between neighboring tiles,  yielding $P=\\lceil H/m\\rceil \\lceil W/m\\rceil$ tiles per channel, $C$.\n",
    "\n",
    "$F(m\\times m, r\\times r)$ is then computed for each tile and filter combination in each channel, and the results are summed over all channels.\n",
    "\n",
    "Substituting $U=GgG^T$ and $V=B^TdB$, we have $Y=A^T[U \\odot V]A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Self-Checking and Error Correction\n",
    "\n",
    "#### (3.1) Self-Checking\n",
    "\n",
    "###### (3.1.1) Multiplication Encoder:\n",
    "\n",
    "All fixed-point systems are transferred to all integer systems. The encoder is to multiply the message word by $A$ (or symbol $M$ instead).\n",
    "\n",
    "###### (3.1.2) Round-off encoder: \n",
    "\n",
    "For message integer $x$, the product-preserving code will be $A\\lceil x/A\\rceil$\n",
    "\n",
    "###### (3.1.3) Barret-Reduction Modulo operation for $M = 2^n-1$ $\\Rightarrow$ **checksum**\n",
    "\n",
    "#### (3.2) Error Correction for 2D CNN\n",
    "\n",
    "If the multiplier errors dominate computation error model, then let $U \\odot V$ is the multiplication matrix. We can take the 2-dimensional error location technique to correct the multiplication. $A^T(U \\odot V)A$ can then be self-checking again.\n",
    "\n",
    "For experiments, BLER analysis can be done for the ECC-part, and the error rate can be reduced again by $1/A$. A big table should be done to compare at least 5 cases and list their basic properties, Winograd reduction rate, decoder overhead, improved MTBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT = \n",
      "⎡1  1  1   0⎤\n",
      "⎢           ⎥\n",
      "⎣0  1  -1  1⎦\n",
      "\n",
      "G = \n",
      "⎡ 1    0     0 ⎤\n",
      "⎢              ⎥\n",
      "⎢1/2  1/2   1/2⎥\n",
      "⎢              ⎥\n",
      "⎢1/2  -1/2  1/2⎥\n",
      "⎢              ⎥\n",
      "⎣ 0    0     1 ⎦\n",
      "\n",
      "BT = \n",
      "⎡1  0   -1  0⎤\n",
      "⎢            ⎥\n",
      "⎢0  1   1   0⎥\n",
      "⎢            ⎥\n",
      "⎢0  -1  1   0⎥\n",
      "⎢            ⎥\n",
      "⎣0  -1  0   1⎦\n",
      "\n",
      "FIR filter: AT*((G*g)(BT*d)) =\n",
      "⎡d[0]⋅g[0] + d[1]⋅g[1] + d[2]⋅g[2]⎤\n",
      "⎢                                 ⎥\n",
      "⎣d[1]⋅g[0] + d[2]⋅g[1] + d[3]⋅g[2]⎦\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wincnn.showCookToomFilter((0, 1, -1), 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
